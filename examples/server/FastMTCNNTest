#from facenet_pytorch import MTCNN
from PIL import Image
import torch
from imutils.video import FileVideoStream
import cv2
import time
import glob
from PIL import Image
import numpy as np
from matplotlib import pyplot as plt
from fast_mtcnn import FastMTCNN

device = 'cuda' if torch.cuda.is_available() else 'cpu'
#device = 'cpu'

filenames = glob.glob('./*.mp4')


def run_detection(fast_mtcnn, filenames):
    frames = []
    frames_processed = 0
    faces_detected = 0
    batch_size = 60
    start = time.time()

    for filename in filenames:

        v_cap = FileVideoStream(filename).start()
        v_len = int(v_cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))

        for j in range(v_len):

            frame = v_cap.read()
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)

            if len(frames) >= batch_size or j == v_len - 1:

                faces = fast_mtcnn(frames)

                frames_processed += len(frames)
                faces_detected += len(faces)
                if len(faces) > 0:
                    print("We detected some faces")
                    curr_frame = Image.fromarray(faces[0])
                    plt.figure(figsize=(12, 8))
                    plt.imshow(curr_frame)
                    plt.axis("off")
                frames = []

                print(
                    f'Frames per second: {frames_processed / (time.time() - start):.3f},',
                    f'faces detected: {faces_detected}\r',
                    end=''
                )

        v_cap.stop()

def run_cam_detection(fast_mtcnn):
    '''Performs without lagging, 0.05 sec per prediction with batch 1'''
    video_capture = cv2.VideoCapture(1)
    frames = []
    while True:
        # Capture frame-by-frame
        ret, frame = video_capture.read()

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
        start = time.time()
        faces = fast_mtcnn(frames)
        if len(faces) > 0 and all(faces[0].shape) > 0:
            print("Show faces!")
            faces[0] = cv2.resize(faces[0], (160, 160))
            cv2.imshow('Video', faces[0])
        else:
            cv2.imshow('Video', frame)

        print(time.time() - start)
        frames = []
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    # When everything is done, release the capture
    video_capture.release()
    cv2.destroyAllWindows()


def run_cam_detection_batch(fast_mtcnn, batch_size=12):
    '''Performs without lagging, 0.05 sec per prediction with batch 12'''
    video_capture = cv2.VideoCapture(1)
    frames = []
    while True:
        # Capture frame-by-frame
        ret, frame = video_capture.read()

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        frames.append(frame)
        if len(frames) >= batch_size:
            start = time.time()
            faces = fast_mtcnn(frames)
            if len(faces) > 0 and all(faces[-1].shape) > 0:
                print("Show faces!")
                faces[-1] = cv2.resize(faces[-1], (160, 160))
                cv2.imshow('Video', faces[-1])
            else:
                 cv2.imshow('Video', frame)

            print(time.time() - start)
            frames = []
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    # When everything is done, release the capture
    video_capture.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":

    fast_mtcnn = FastMTCNN(
        stride=4,
        resize=1,
        margin=14,
        factor=0.6,
        keep_all=True,
        device=device
        #,post_process=False

    )
    filenames = glob.glob('./*.mp4')

    run_cam_detection(fast_mtcnn)

